{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3907428b-5edb-472b-a29b-f7facb915cfb",
   "metadata": {
    "id": "3907428b-5edb-472b-a29b-f7facb915cfb"
   },
   "source": [
    "# 3. ConvLSTM\n",
    "\n",
    "![convlstm](https://miro.medium.com/max/942/1*u8neecA4w6b_F1NgnyPP0Q.png)\n",
    "\n",
    "For the last sample submission, we are going to cover **ConvLSTM** that are frequently used for future video frame prediction. In addition to that, we are going to mix up things a bit. \n",
    "First of all, we are going to use TensorFlow rather than PyTorch, just to demonstrate how the former can be used to make a valid submission. Consequently, we are not going to use a separate ```model.py``` script and instead, the model is going to be trained within the following notebook and saved for the further use. Lastly, we are going to use MSE loss (used in some papers).\n",
    "\n",
    "## Theory\n",
    "\n",
    "![LSTM cell](https://miro.medium.com/max/1400/1*ujzOtlfaJFWhKb6HS9RS-g.png)\n",
    "\n",
    "As the name of the model migth suggest, **ConvLSTM** system combines Convolutional layers with the Long Short Term Memory architecture. Applying such combination to our problem seems to be quite logical: we are dealing with visual data in which the order of elements matters.\n",
    "\n",
    "In short, ConvLSTM approach is as follows:\n",
    "\n",
    "- **Convolutional layers**. Image is first passed through some Convolutional layers to filter important features.\n",
    "- These features are then connected with fully-connected **Dense network**.\n",
    "- The 3D input is then passed though LSTM architecture.\n",
    "\n",
    "Fortunately to us, Keras already has a predefined ConvLSTM layer that can be used to implement such system. The parameters set inside the ```ConvLSTM``` function remain similar to those in the regular ```Conv``` layer, the main difference appears in the input (as well as output) dimensions - it will become more clear as be go through.\n",
    "\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Before implementing ConvLSTM system, we first have to decide on the exact approach we are going to take for the this problem. As we know, we have twelve 128x128 images as our input and we have to produce twenty-four 64x64 future images.\n",
    "\n",
    "So far, we built models that took all twelve images as an input and produced twenty-four reduced images which increased the number of parameters in our model significantly. The following implementation will take a bit different approach:\n",
    "\n",
    "- The input images will be **resized to 64x64** prior to passing them through the model\n",
    "- Model will be trained to predict a **consecutive frame** rather than 24 new frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c976a",
   "metadata": {},
   "source": [
    "#### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccebc6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from numpy import float32\n",
    "from dataset import ClimateHackDataset\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd438750",
   "metadata": {},
   "source": [
    "#### Loading data\n",
    "\n",
    "As the following implementation will use TensorFlow instead of PyTorch, we are going to import different ```dataset.py``` script than in the previous cases. In addition, we are no longer loading 12 and 24 images for the input-output data - as we are predicting the consecutive term, we are importing one image for each input-output pair. Other than that, the process of loading data remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37645467",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = ____\n",
    "EPOCHS = ____\n",
    "\n",
    "#Defining path\n",
    "ch_dataset = ClimateHackDataset(____, crops_per_slice=2)\n",
    "coordinates, features, labels = ch_dataset.load_data()\n",
    "\n",
    "#Expanding dimensions of our features and labels\n",
    "features = ____\n",
    "labels = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebc7d6",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "Prior to building the ConvLSTM system, we need to preprocess our image data. The input image (128x128) has to be resized to (64x64) followed by normalization.\n",
    "\n",
    "In addition, we need to make sure that our input data has the right number of dimensions. Similar to the regular Convolutional layers, we will need the final three dimensions that will corespond to height, width and the number of channels. In addition to that, we have already expanded the initial 3-dimensional imagery data to 4 dimensions (image sample). As the sequence of data matters, we need to add the additional 5th dimension, therefore, the previously described normalization will be followed by dimension expansion.\n",
    "\n",
    "Overall, our input to ConvLSTM layer will have the shape of ```(batch_size, frame_num, width, height, channels)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcda900",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = features[:, 0, :, :, :]\n",
    "# Resizing images to 64x64\n",
    "X = ____\n",
    "# Expanding dimensions in axis = 1\n",
    "X = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4071b6a",
   "metadata": {},
   "source": [
    "#### Building model\n",
    "\n",
    "We will use ConvLSTM system presented in [this paper](https://papers.nips.cc/paper/2015/file/07563a3fe3bbe7e3ba84431ad9d055af-Paper.pdf). In short, it will contain:\n",
    "\n",
    "- 3 **ConvLSTM2D** layers\n",
    "- 2 **batch normalization** layers in between\n",
    "- Last **Conv3D** layer for spatiotemporal resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = layers.Input(shape=(None, *X.shape[2:]))\n",
    "\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(5, 5),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(inp)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = ____(x)\n",
    "x = ____(x)\n",
    "\n",
    "x = ____(x)\n",
    "\n",
    "x = layers.Conv3D(\n",
    "    filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
    ")(x) * 1023\n",
    "\n",
    "model = ____\n",
    "\n",
    "model.compile(loss=____, optimizer=____)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1735a",
   "metadata": {},
   "source": [
    "Before training our model, it is also crucial to check that the number of dimensions throughout all layers are correct and we are getting the output we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d119ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking model's structure\n",
    "model.____()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b2338",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142cee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, labels, batch_size = ____, epochs = ____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c373e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the training, make sure to save your model\n",
    "model.save(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83ce60",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "\n",
    "Before preparing the ```evaluation.py``` script and submitting our model, let's look at sample prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8733d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading sample image\n",
    "img = ____\n",
    "\n",
    "# Resizing and normalizing image\n",
    "img = np.expand_dims(tf.image.resize(img, (64, 64)), axis = 0) / 1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7202655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "model = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53482439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating prediction\n",
    "pred = ____\n",
    "\n",
    "# Reducing dimensions to visualize image\n",
    "pred = np.squeeze(np.squeeze(pred, axis = 0), axis = 0)\n",
    "\n",
    "plt.imshow(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d8d9c",
   "metadata": {},
   "source": [
    "#### Deploying model\n",
    "\n",
    "The only custom script that needs to be changed for such system is the ```evaluation.py```. Within the script, you will need to:\n",
    "- Load the model\n",
    "- Preprocess the last image from the given twelve images\n",
    "- Pass image through the model\n",
    "- Use generated image as a new input for the model\n",
    "- Repeat the last two steps until you have 24 images\n",
    "\n",
    "***Depending on the time you are reading this source, such scripts may already be available to use***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of load_and_plot_HRV_UK_Zarr_from_GCS.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "6f774df9e68be78be8fedc92c8cad2f0688a777ad163558f0717eecbd1f23d05"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
